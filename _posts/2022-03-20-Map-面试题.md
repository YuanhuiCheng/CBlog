### HashMap

- 默认初始化大小为 16，之后每次扩容，容量都变为原来 2 倍。并且，总是使用 2 的幂作为哈希表大小。
- JDK 1.8 之前

  - 数组 + 链表
  - key 的 `hashcode` 经过扰动函数（可以减少碰撞）处理后得到 `hash` 值，然后通过 `(n-1)&hash` 判断当前元素存放的位置 `((n-1)&hash = hash%n)`。
    - 为什么 n 是 2 的倍数？
      - 使得添加的元素均匀分布在 hashmap 每个位置上，减少 hash 碰撞；
      - 当 n 是 2 的倍数时，`((n-1)&hash = hash%n)`。使用 `&` 能大大增加计算效率。
  - 相比较于 1.8 的 `hash` 方法，1.7 的 `hash` 方法性能稍差，因为扰动了 4 次。
  - `put` 操作采用头插法
    - 头插法的弊端：链表成环

![头插法链表成环](https://github.com/YuanhuiCheng/YuanhuiCheng.github.io/raw/gh-pages/imgs/map-chain.jpg)

- JDK 1.8 及之后

  - 当链表长度大于阈值（默认为 8）时，调用 `treeifyBin()`。这个方法会根据 hashmap 数组来决定是否转换为红黑树。只有当数组大于等于 64 时，才会执行红黑树操作，以减少搜索时间。否则就是执行 `resize()` 对数组扩容。
  - hashmap 类里有两个属性：`loadFactor` 和 `threshold`;
    - `loadFactor` 控制数组存放数据的疏密程度。越趋近于 1，数组中存放的数据 (entry) 就越多，也就越密，也就会让链表的长度增加；
    - `loadFactor` 太大导致查找元素效率越低。默认值 `0.75f` 是官方给出的一个比较好的临界值；
    - 给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据。当数据量达到了 `16*0.75=12` 就需要将当前 16 的容量进行扩容。而扩容这个过程涉及到 `rehash`，复制等操作，所以非常消耗性能。
  - `put` 操作：
    - 如果定位到的数组位置没有元素，就直接插入；
    - 如果定位到的数组位置有元素就要和插入的 key 比较。如果 key 相同就直接覆盖；如果 key 不相同，就判断 p 是否是一个树节点。如果是就调用 `e=(TreeNode<K,V>p).putTreeVal(this, tab, hash, value)` 将元素添加进入。如果不是就遍历链表插入（尾插法）；
  - 扩容 (resize)
    - 什么时候会扩容？
      - 空参构造函数：实例化的 HashMap 默认内部数组是 null，即没有实例化。第一次调用 put 方法时，则会开始第一次初始化扩容，长度为 16；
      - 有参构造函数：会根据指定的正整数找到不小于指定容量的 2 的幂数；
      - 如果不是第一次扩容，则容量变为原来的 2 倍；
    - JDK 11 `resize()` 源码

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                    oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                    (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

### ConcurrentHashMap

- Java 1.7 `Segment + HashEntry` 分段锁

  - `Segment` 继承自 `ReentrantLock`;
  - `Segment[] -> HashEntry[] -> key, value, next`
  - `put` 过程使用 `ReentrantLock` 加锁，如果获取锁失败尝试自旋，自旋超过次数就阻塞获取；
  - `get` 过程用 `volatile` 修饰值，永远拿到最新值；
  - 每一个 `HashEntry` 数组都可以扩容，但是 `Segment` 数组一旦初始化就不可改变，默认 `Segment` 个数是 16，也可以认为 `ConcurrentHashMap` 默认支持最多 16 个线程并发；
- Java 1.8 抛弃了 `Segment`，改为使用 `CAS + Synchronized + Node` 实现，同时加入红黑树

  - `Node[] -> key, value, next`
  - `put` 过程：
    - 首先计算 `hash`，遍历 `node` 数组，如果 `node` 为空，通过 `CAS + 自旋` 的方式初始化；查找，赋值，替换都使用 `CAS`;
    - 如果 `hash == MOVED == -1`，说明需要扩容，执行扩容；
    - 如果都不满足，使用 `Synchronized` 写入数据；`Synchronized` 锁的是链表 `head` 节点，不影响其他元素读写。扩容时阻塞所有的读写操作，并发扩容。读操作无锁。`Node` 的 `val` 和 `next` 使用 `volatile` 修饰，读写线程对该变量互相可见。数组用 `volatile` 修饰，保证扩容时被线程感知；
    - 如果数量大于 `TREEIFY_THRESHOLD`，则要转换为红黑树；
  - 从源码可以发现 `ConcurrentHashMap` 的初始化是通过自旋和 `CAS` 操作完成的，里面需要注意的是变量 `sizeCtl`，它的值决定着当前的初始值状态：
    - `= -1` 标记作用，告知其他线程，说明正在初始化；
    - `= 0` 表示没有指定初始容量；
    - `= -N` 说明有 `N-1` 个线程正在进行扩容；
    - `> 0`，表示 `table` 初始化大小（容量）；
    - `= 0.75n`，扩容阈值；
